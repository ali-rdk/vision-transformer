{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:34:06.143856Z",
     "start_time": "2025-10-16T12:33:52.535834Z"
    },
    "id": "IVjJZHNafqPW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:35:26.949036Z",
     "start_time": "2025-10-16T12:35:26.901891Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZhlXkW_g6RT",
    "outputId": "f8400306-480b-446f-d250-e8a825cf349f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# def set_seeds(seed):\n",
    "#     os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed_all(seed)\n",
    "#\n",
    "# set_seeds(2025)\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:34:06.204307Z",
     "start_time": "2025-10-16T12:34:06.201562Z"
    },
    "id": "4-d2mmZrg71R"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:34:06.216866Z",
     "start_time": "2025-10-16T12:34:06.212791Z"
    },
    "id": "xvvpO96HhAGD"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    # transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    # transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:34:06.521399Z",
     "start_time": "2025-10-16T12:34:06.227588Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train_set, valid_set = random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:34:06.533221Z",
     "start_time": "2025-10-16T12:34:06.528433Z"
    },
    "id": "dAdsJT18jhhc"
   },
   "outputs": [],
   "source": [
    "def patchify(images, patch_no):\n",
    "  n, c, h, w = images.shape\n",
    "\n",
    "  patches = torch.zeros(n, patch_no ** 2, (h*c*w) // patch_no ** 2 , device=images.device)\n",
    "  patch_size = h // patch_no\n",
    "\n",
    "  for idx, image in enumerate(images):\n",
    "    for i in range(patch_no):\n",
    "      for j in range(patch_no):\n",
    "        patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]\n",
    "        patches[idx, i * patch_no + j] = patch.flatten()\n",
    "  return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:34:06.546306Z",
     "start_time": "2025-10-16T12:34:06.543152Z"
    },
    "id": "m1iroln_w76X"
   },
   "outputs": [],
   "source": [
    "def get_positional_embeddings(sequence_length, dimension):\n",
    "    result = torch.ones(sequence_length, dimension)\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(dimension):\n",
    "            result[i][j] = np.sin(i / (10000 ** (j / dimension))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / dimension)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:34:06.560120Z",
     "start_time": "2025-10-16T12:34:06.554781Z"
    },
    "id": "Td56unea0OOp"
   },
   "outputs": [],
   "source": [
    "class Multi_Self_Attention(nn.Module):\n",
    "    def __init__(self, dimension, head_no, dropout=0.1):\n",
    "        super(Multi_Self_Attention, self).__init__()\n",
    "        self.dimension = dimension\n",
    "        self.head_no = head_no\n",
    "        self.head_dimension = dimension // head_no\n",
    "\n",
    "        self.query = nn.Linear(dimension, dimension)\n",
    "        self.key = nn.Linear(dimension, dimension)\n",
    "        self.value = nn.Linear(dimension, dimension)\n",
    "        self.out = nn.Linear(dimension, dimension)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, dimension = x.size()\n",
    "\n",
    "        q = self.query(x).view(batch_size, seq_len, self.head_no, self.head_dimension).transpose(1, 2)\n",
    "        k = self.key(x).view(batch_size, seq_len, self.head_no, self.head_dimension).transpose(1, 2)\n",
    "        v = self.value(x).view(batch_size, seq_len, self.head_no, self.head_dimension).transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dimension ** 0.5)\n",
    "        attn = self.softmax(scores)\n",
    "        context = torch.matmul(attn, v)\n",
    "\n",
    "        context = context.transpose(1, 2).reshape(batch_size, seq_len, dimension)\n",
    "        out = self.dropout(self.out(context))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:34:06.573592Z",
     "start_time": "2025-10-16T12:34:06.569319Z"
    },
    "id": "xophe6gj1BWc"
   },
   "outputs": [],
   "source": [
    "class ViT_Block(nn.Module):\n",
    "  def __init__(self, hidden_dimension, head_no, mlp_ratio=4, dropout=0.1):\n",
    "    super(ViT_Block, self).__init__()\n",
    "    self.hidden_dimension = hidden_dimension\n",
    "    self.head_no = head_no\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.norm1 = nn.LayerNorm(hidden_dimension)\n",
    "    self.multi_head_self_attention = Multi_Self_Attention(hidden_dimension, head_no, dropout)\n",
    "    self.norm2 = nn.LayerNorm(hidden_dimension)\n",
    "\n",
    "    self.mlp = nn.Sequential(\n",
    "        nn.Linear(hidden_dimension, mlp_ratio * hidden_dimension),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(mlp_ratio * hidden_dimension, hidden_dimension)\n",
    "    )\n",
    "\n",
    "  def forward(self, input):\n",
    "    attention = input + self.dropout(self.multi_head_self_attention(self.norm1(input)))\n",
    "    out = attention + self.dropout(self.mlp(self.norm2(attention)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:34:06.681434Z",
     "start_time": "2025-10-16T12:34:06.584514Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5mrHPvo6SXT",
    "outputId": "fece8ca1-440d-4708-c4dd-e14590364602"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 50, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ViT_Block(hidden_dimension=8, head_no=2)\n",
    "x = torch.randn(7, 50, 8)\n",
    "test(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:35:37.508394Z",
     "start_time": "2025-10-16T12:35:36.861570Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xkfHNquhlpb",
    "outputId": "aef62cae-84e8-473e-a314-c09a9a51a1f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "ViT_Model                                     [64, 10]                  256\n",
       "├─Linear: 1-1                                 [64, 16, 256]             12,800\n",
       "├─ModuleList: 1-2                             --                        --\n",
       "│    └─ViT_Block: 2-1                         [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-1                    [64, 17, 256]             512\n",
       "│    │    └─Multi_Self_Attention: 3-2         [64, 17, 256]             263,168\n",
       "│    │    └─Dropout: 3-3                      [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-4                    [64, 17, 256]             512\n",
       "│    │    └─Sequential: 3-5                   [64, 17, 256]             525,568\n",
       "│    │    └─Dropout: 3-6                      [64, 17, 256]             --\n",
       "│    └─ViT_Block: 2-2                         [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-7                    [64, 17, 256]             512\n",
       "│    │    └─Multi_Self_Attention: 3-8         [64, 17, 256]             263,168\n",
       "│    │    └─Dropout: 3-9                      [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-10                   [64, 17, 256]             512\n",
       "│    │    └─Sequential: 3-11                  [64, 17, 256]             525,568\n",
       "│    │    └─Dropout: 3-12                     [64, 17, 256]             --\n",
       "│    └─ViT_Block: 2-3                         [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-13                   [64, 17, 256]             512\n",
       "│    │    └─Multi_Self_Attention: 3-14        [64, 17, 256]             263,168\n",
       "│    │    └─Dropout: 3-15                     [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-16                   [64, 17, 256]             512\n",
       "│    │    └─Sequential: 3-17                  [64, 17, 256]             525,568\n",
       "│    │    └─Dropout: 3-18                     [64, 17, 256]             --\n",
       "│    └─ViT_Block: 2-4                         [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-19                   [64, 17, 256]             512\n",
       "│    │    └─Multi_Self_Attention: 3-20        [64, 17, 256]             263,168\n",
       "│    │    └─Dropout: 3-21                     [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-22                   [64, 17, 256]             512\n",
       "│    │    └─Sequential: 3-23                  [64, 17, 256]             525,568\n",
       "│    │    └─Dropout: 3-24                     [64, 17, 256]             --\n",
       "│    └─ViT_Block: 2-5                         [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-25                   [64, 17, 256]             512\n",
       "│    │    └─Multi_Self_Attention: 3-26        [64, 17, 256]             263,168\n",
       "│    │    └─Dropout: 3-27                     [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-28                   [64, 17, 256]             512\n",
       "│    │    └─Sequential: 3-29                  [64, 17, 256]             525,568\n",
       "│    │    └─Dropout: 3-30                     [64, 17, 256]             --\n",
       "│    └─ViT_Block: 2-6                         [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-31                   [64, 17, 256]             512\n",
       "│    │    └─Multi_Self_Attention: 3-32        [64, 17, 256]             263,168\n",
       "│    │    └─Dropout: 3-33                     [64, 17, 256]             --\n",
       "│    │    └─LayerNorm: 3-34                   [64, 17, 256]             512\n",
       "│    │    └─Sequential: 3-35                  [64, 17, 256]             525,568\n",
       "│    │    └─Dropout: 3-36                     [64, 17, 256]             --\n",
       "├─Sequential: 1-3                             [64, 10]                  --\n",
       "│    └─LayerNorm: 2-7                         [64, 256]                 512\n",
       "│    └─GELU: 2-8                              [64, 256]                 --\n",
       "│    └─Linear: 2-9                            [64, 256]                 65,792\n",
       "│    └─Dropout: 2-10                          [64, 256]                 --\n",
       "│    └─GELU: 2-11                             [64, 256]                 --\n",
       "│    └─Linear: 2-12                           [64, 10]                  2,570\n",
       "===============================================================================================\n",
       "Total params: 4,820,490\n",
       "Trainable params: 4,820,490\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 308.49\n",
       "===============================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 149.43\n",
       "Params size (MB): 19.28\n",
       "Estimated Total Size (MB): 168.91\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ViT_Model(nn.Module):\n",
    "  def __init__(self, data_shape, patch_no, hidden_dimension, output_dimension, block_no, head_no):\n",
    "    super(ViT_Model, self).__init__()\n",
    "\n",
    "    self.data_shape = data_shape\n",
    "    self.patch_no = patch_no\n",
    "    self.hidden_dimension = hidden_dimension\n",
    "    self.block_no = block_no\n",
    "    self.head_no = head_no\n",
    "\n",
    "    self.patch_size = (data_shape[1] // patch_no, data_shape[2] // patch_no)\n",
    "    self.data_dimension = int(self.data_shape[0] * self.patch_size[0] * self.patch_size[1])\n",
    "\n",
    "    self.mapper = nn.Linear(self.data_dimension, self.hidden_dimension)\n",
    "\n",
    "    self.class_token = nn.Parameter(torch.rand(1, self.hidden_dimension))\n",
    "\n",
    "    self.register_buffer(\n",
    "            'positional_embedding',\n",
    "            get_positional_embeddings(patch_no ** 2 + 1, hidden_dimension),\n",
    "            persistent=False\n",
    "        )\n",
    "\n",
    "    self.blocks = nn.ModuleList([ViT_Block(self.hidden_dimension, self.head_no, dropout=0.1) for _ in range(self.block_no)])\n",
    "\n",
    "    self.mlp_head = nn.Sequential(\n",
    "        nn.LayerNorm(self.hidden_dimension),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(self.hidden_dimension, self.hidden_dimension),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(self.hidden_dimension, output_dimension)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, input):\n",
    "    patches = patchify(input, self.patch_no)\n",
    "    tokens = self.mapper(patches)\n",
    "\n",
    "    tokens = torch.stack([torch.vstack((self.class_token, tokens[i])) for i in range(len(tokens))])\n",
    "\n",
    "    positional_embedding = self.positional_embedding.repeat(input.shape[0], 1, 1)\n",
    "    out = tokens + positional_embedding\n",
    "\n",
    "    for block in self.blocks:\n",
    "      out = block(out)\n",
    "\n",
    "    out = out[:, 0]\n",
    "\n",
    "    out = self.mlp_head(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "model = ViT_Model(data_shape=(1, 28, 28), patch_no=4, hidden_dimension=256, output_dimension=10, block_no=6, head_no=8).to(device)\n",
    "\n",
    "input_data = torch.randn(BATCH_SIZE, 1, 28, 28).to(device)\n",
    "summary(model, input_data=input_data, device=str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:35:46.325792Z",
     "start_time": "2025-10-16T12:35:46.320622Z"
    },
    "id": "u-YjUisdrcrO"
   },
   "outputs": [],
   "source": [
    "epoch_no = 10\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T12:55:57.746850Z",
     "start_time": "2025-10-16T12:35:48.213920Z"
    },
    "id": "2dXq3VE0CSf9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd2a7a2940c4d1a80c3219b8a401118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2cd7f43e3d3459da3c1b9b7f2a62426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 training:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 average training loss: 0.6756\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ece78a1f4b4d63bc5d3b143491c07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 testing:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 average test loss: 0.3983\n",
      "Epoch 1/10 test accuracy: 87.62%\n",
      "********************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4e83573f7347bca8912d9062e6c6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 training:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 average training loss: 0.3367\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9595287a2414a0391664470eeb212d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 testing:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 average test loss: 0.2986\n",
      "Epoch 2/10 test accuracy: 90.26%\n",
      "********************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dab7908cceb4143b270a348b6025e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 training:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 average training loss: 0.3180\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3fa77c3130435c923f3d9fc44fd470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 testing:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 average test loss: 0.2633\n",
      "Epoch 3/10 test accuracy: 91.76%\n",
      "********************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02d9f94fa9a4eb7ae6607b3a0009ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 training:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 average training loss: 0.3463\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53e48a8fceb435c9504c080ecbe4ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 testing:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 average test loss: 0.2417\n",
      "Epoch 4/10 test accuracy: 92.46%\n",
      "********************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b36ddeaa6404a2e8c0997695e734a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 training:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 average training loss: 0.2678\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e06491742bb46e4b542c2a3d5bc6bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 testing:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 average test loss: 0.2081\n",
      "Epoch 5/10 test accuracy: 93.46%\n",
      "********************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8982c781f9bb4f5cbd1218e111231074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 training:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 average training loss: 0.3272\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245f8f0feb4340d498a8e8d69f4804eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 testing:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 average test loss: 0.2003\n",
      "Epoch 6/10 test accuracy: 93.87%\n",
      "********************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0156c9cb3903496b8678181388215315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 training:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 average training loss: 0.2091\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934d5c45f4694a0181760da0af948d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 testing:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 average test loss: 0.1959\n",
      "Epoch 7/10 test accuracy: 94.04%\n",
      "********************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2366d99712e7487dafccf384b4a7accf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 training:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 average training loss: 0.2298\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c42d3eb82f149b5a72f08d715c1c8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 testing:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 average test loss: 0.2295\n",
      "Epoch 8/10 test accuracy: 92.96%\n",
      "********************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ecfb68a36c43ed98ec873eab913ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 training:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 average training loss: 0.3042\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8964c40f0c14ceea6d466ce47f1f247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 testing:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 average test loss: 0.2694\n",
      "Epoch 9/10 test accuracy: 91.40%\n",
      "********************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc6a2d547c5497a8aac8f48fbe5b891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 training:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 average training loss: 0.2494\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c309b04294084b4f92ae058fcf8ceb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 testing:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 average test loss: 0.1989\n",
      "Epoch 10/10 test accuracy: 93.45%\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(1, epoch_no + 1), desc=\"Epochs\")\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    print(f\"********************************************************************\")\n",
    "    epoch_progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch} training\")\n",
    "    for batch_no, (data, labels) in epoch_progress_bar:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = train_loss / num_batches\n",
    "    print(f\"Epoch {epoch}/{epoch_no} average training loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"----------------------------------------------------------------\")\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_test_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_progress_bar = tqdm(enumerate(test_loader), total=len(test_loader), desc=f\"Epoch {epoch} testing\")\n",
    "        for batch_no, (data, labels) in test_progress_bar:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, labels)\n",
    "            test_loss += loss.item()\n",
    "            num_test_batches += 1\n",
    "\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / num_test_batches\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Epoch {epoch}/{epoch_no} average test loss: {avg_test_loss:.4f}\")\n",
    "    print(f\"Epoch {epoch}/{epoch_no} test accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
